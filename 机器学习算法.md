线性回归:使用直线或超平面拟合数据，预测位置数据的值

逻辑回归:将线性回归结果映射到0-1之间

正则化：是其他算法（通常是回归算法）的延伸，根据算法的复杂度对算法进行调整，对复杂模型进行惩罚  
L1正则化 L2正则化  

最小二乘法：令算式函数对每个参数偏导数为0，直接求出各个参数。

梯度下降法：设置一个步长，更新参数为（原始值-（步长*偏导数）），反复迭代。


分类及回归树（CART）：使用**基尼指数**来选择属性划分，选择基尼指数最小的属性作为最优划分属性。基尼指数反映从数据集中随机抽取两个样本，其类别标记不一致的概率。  
ID3 (Iterative Dichotomiser 3)决策树：以**信息熵的下降速度**为选取测试属性的标准，即在每个节点选取还尚未被用来划分的具有**最高信息增益**的属性作为划分标准，然后继续这个过程，直到生成的决策树能完美分类训练样例  
C4.5决策树：通过信息增益率选择分裂属性；先从候选划分属性中招数信息增益高于平均水平的属性，再从中选择增益率最高的。  
随机森林：随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，每棵决策树都是一个分类器（假设现在针对的是分类问题），那么对于一个输入样本，N棵树会有N个分类结果。而随机森林集成了所有的分类投票结果，将投票次数最多的类别指定为最终的输出


BP算法：
Bagging和Boosting

k-Nearest Neighbor(KNN)：


